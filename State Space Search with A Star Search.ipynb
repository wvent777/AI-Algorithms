{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Space Search with A* Search\n",
    "\n",
    "You are going to implement the A\\* Search algorithm for navigation problems.\n",
    "\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Search is often used for path-finding in video games. Although the characters in a video game often move in continuous spaces,\n",
    "it is trivial to layout a \"waypoint\" system as a kind of navigation grid over the continuous space. Then if the character needs\n",
    "to get from Point A to Point B, it does a line of sight (LOS) scan to find the nearest waypoint (let's call it Waypoint A) and\n",
    "finds the nearest, LOS waypoint to Point B (let's call it Waypoint B). The agent then does a A* search for Waypoint B from Waypoint A to find the shortest path. The entire path is thus Point A to Waypoint A to Waypoint B to Point B.\n",
    "\n",
    "We're going to simplify the problem by working in a grid world. The symbols that form the grid have a special meaning as they\n",
    "specify the type of the terrain and the cost to enter a grid cell with that type of terrain:\n",
    "\n",
    "```\n",
    "token   terrain    cost \n",
    "🌾       plains     1\n",
    "🌲       forest     3\n",
    "🪨       hills      5\n",
    "🐊       swamp      7\n",
    "🗻       mountains  impassible\n",
    "```\n",
    "\n",
    "We can think of the raw format of the map as being something like:\n",
    "\n",
    "```\n",
    "🌾🌾🌾🌾🌲🌾🌾\n",
    "🌾🌾🌾🌲🌲🌲🌾\n",
    "🌾🗻🗻🗻🌾🌾🌾\n",
    "🌾🌾🗻🗻🌾🌾🌾\n",
    "🌾🌾🗻🌾🌾🌲🌲\n",
    "🌾🌾🌾🌾🌲🌲🌲\n",
    "🌾🌾🌾🌾🌾🌾🌾\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The World\n",
    "\n",
    "Given a map like the one above, we can easily represent each row as a `List` and the entire map as `List of Lists`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_world = [\n",
    "['🌾', '🌾', '🌾', '🌾', '🌾', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾'],\n",
    "['🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌾', '🌾', '🗻', '🗻', '🗻', '🗻', '🗻', '🗻', '🗻', '🌾', '🌾'],\n",
    "['🌾', '🌾', '🌾', '🌾', '🗻', '🗻', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🗻', '🗻', '🗻', '🪨', '🪨', '🪨', '🗻', '🗻', '🪨', '🪨'],\n",
    "['🌾', '🌾', '🌾', '🌾', '🪨', '🗻', '🗻', '🗻', '🌲', '🌲', '🌲', '🌲', '🐊', '🐊', '🌲', '🌲', '🌲', '🌲', '🌲', '🌾', '🌾', '🪨', '🪨', '🗻', '🗻', '🪨', '🌾'],\n",
    "['🌾', '🌾', '🌾', '🪨', '🪨', '🗻', '🗻', '🌲', '🌲', '🌾', '🌾', '🐊', '🐊', '🐊', '🐊', '🌲', '🌲', '🌲', '🌾', '🌾', '🌾', '🪨', '🗻', '🗻', '🗻', '🪨', '🌾'],\n",
    "['🌾', '🪨', '🪨', '🪨', '🗻', '🗻', '🪨', '🪨', '🌾', '🌾', '🌾', '🌾', '🐊', '🐊', '🐊', '🐊', '🐊', '🌾', '🌾', '🌾', '🌾', '🌾', '🪨', '🗻', '🪨', '🌾', '🌾'],\n",
    "['🌾', '🪨', '🪨', '🗻', '🗻', '🪨', '🪨', '🌾', '🌾', '🌾', '🌾', '🪨', '🗻', '🗻', '🗻', '🐊', '🐊', '🐊', '🌾', '🌾', '🌾', '🌾', '🌾', '🪨', '🌾', '🌾', '🌾'],\n",
    "['🌾', '🌾', '🪨', '🪨', '🪨', '🪨', '🪨', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🪨', '🗻', '🗻', '🗻', '🐊', '🐊', '🐊', '🌾', '🌾', '🪨', '🪨', '🪨', '🌾', '🌾'],\n",
    "['🌾', '🌾', '🌾', '🪨', '🪨', '🪨', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🪨', '🪨', '🗻', '🗻', '🌾', '🐊', '🐊', '🌾', '🌾', '🪨', '🪨', '🪨', '🌾', '🌾', '🌾'],\n",
    "['🌾', '🌾', '🌾', '🐊', '🐊', '🐊', '🌾', '🌾', '🪨', '🪨', '🪨', '🗻', '🗻', '🗻', '🗻', '🌾', '🌾', '🌾', '🐊', '🌾', '🪨', '🪨', '🪨', '🌾', '🌾', '🌾', '🌾'],\n",
    "['🌾', '🌾', '🐊', '🐊', '🐊', '🐊', '🐊', '🌾', '🪨', '🪨', '🗻', '🗻', '🗻', '🪨', '🌾', '🌾', '🌾', '🌾', '🌾', '🪨', '🗻', '🗻', '🗻', '🪨', '🌾', '🌾', '🌾'],\n",
    "['🌾', '🐊', '🐊', '🐊', '🐊', '🐊', '🌾', '🌾', '🪨', '🗻', '🗻', '🪨', '🌾', '🌾', '🌾', '🌾', '🐊', '🐊', '🌾', '🌾', '🪨', '🗻', '🗻', '🪨', '🌾', '🌾', '🌾'],\n",
    "['🐊', '🐊', '🐊', '🐊', '🐊', '🌾', '🌾', '🪨', '🪨', '🗻', '🗻', '🪨', '🌾', '🐊', '🐊', '🐊', '🐊', '🌾', '🌾', '🌾', '🪨', '🗻', '🪨', '🌾', '🌾', '🌾', '🌾'],\n",
    "['🌾', '🐊', '🐊', '🐊', '🐊', '🌾', '🌾', '🪨', '🌲', '🌲', '🪨', '🌾', '🌾', '🌾', '🌾', '🐊', '🐊', '🐊', '🐊', '🌾', '🌾', '🪨', '🌾', '🌾', '🌾', '🌾', '🌾'],\n",
    "['🌾', '🌾', '🌾', '🌾', '🗻', '🌾', '🌾', '🌲', '🌲', '🌲', '🌲', '🪨', '🪨', '🪨', '🪨', '🌾', '🐊', '🐊', '🐊', '🌾', '🌾', '🪨', '🗻', '🪨', '🌾', '🌾', '🌾'],\n",
    "['🌾', '🌾', '🌾', '🗻', '🗻', '🗻', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🗻', '🗻', '🗻', '🪨', '🪨', '🌾', '🐊', '🌾', '🪨', '🗻', '🗻', '🪨', '🌾', '🌾', '🌾'],\n",
    "['🌾', '🌾', '🗻', '🗻', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🗻', '🗻', '🗻', '🌾', '🌾', '🗻', '🗻', '🗻', '🌾', '🌾', '🌾', '🌾', '🌾'],\n",
    "['🌾', '🌾', '🌾', '🗻', '🗻', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🗻', '🗻', '🗻', '🗻', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾'],\n",
    "['🌾', '🌾', '🌾', '🗻', '🗻', '🗻', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌾', '🌾', '🌾', '🪨', '🪨', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾'],\n",
    "['🌾', '🌾', '🌾', '🌾', '🗻', '🗻', '🗻', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🐊', '🐊', '🐊', '🐊'],\n",
    "['🌾', '🌾', '🪨', '🪨', '🪨', '🪨', '🗻', '🗻', '🌲', '🌲', '🌲', '🌲', '🌲', '🌾', '🗻', '🌾', '🌾', '🌾', '🌾', '🌾', '🐊', '🐊', '🐊', '🐊', '🐊', '🐊', '🐊'],\n",
    "['🌾', '🌾', '🌾', '🌾', '🪨', '🪨', '🪨', '🗻', '🗻', '🗻', '🌲', '🌲', '🗻', '🗻', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🐊', '🐊', '🐊', '🐊', '🐊', '🐊', '🐊'],\n",
    "['🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🪨', '🪨', '🪨', '🗻', '🗻', '🗻', '🗻', '🌾', '🌾', '🌾', '🌾', '🪨', '🪨', '🌾', '🌾', '🐊', '🐊', '🐊', '🐊', '🐊', '🐊'],\n",
    "['🌾', '🪨', '🪨', '🌾', '🌾', '🪨', '🪨', '🪨', '🪨', '🪨', '🌾', '🌾', '🌾', '🌾', '🌾', '🪨', '🪨', '🗻', '🗻', '🪨', '🪨', '🌾', '🐊', '🐊', '🐊', '🐊', '🐊'],\n",
    "['🪨', '🗻', '🪨', '🪨', '🪨', '🪨', '🌾', '🌾', '🌾', '🌾', '🌾', '🗻', '🗻', '🗻', '🪨', '🪨', '🗻', '🗻', '🌾', '🗻', '🗻', '🪨', '🪨', '🐊', '🐊', '🐊', '🐊'],\n",
    "['🪨', '🗻', '🗻', '🗻', '🪨', '🌾', '🌾', '🌾', '🌾', '🌾', '🪨', '🪨', '🗻', '🗻', '🗻', '🗻', '🪨', '🪨', '🪨', '🪨', '🗻', '🗻', '🗻', '🐊', '🐊', '🐊', '🐊'],\n",
    "['🪨', '🪨', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🪨', '🪨', '🪨', '🪨', '🪨', '🌾', '🌾', '🌾', '🌾', '🪨', '🪨', '🪨', '🌾', '🌾', '🌾']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning\n",
    "\n",
    "One implication of this representation is that (x, y) is world[ y][ x] so that (3, 2) is world[ 2][ 3] and world[ 7][ 9] is (9, 7). Yes, there are many ways to do this. I picked this representation because when you look at it, it *looks* like a regular x, y cartesian grid and it's easy to print out.\n",
    "\n",
    "It is often easier to begin your programming by operating on test input that has an obvious solution. If we had a small 7x7 world with the following characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_world = [\n",
    "    ['🌾', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲'],\n",
    "    ['🌾', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲'],\n",
    "    ['🌾', '🌲', '🌲', '🌲', '🌲', '🌲', '🌲'],\n",
    "    ['🌾', '🌾', '🌾', '🌾', '🌾', '🌾', '🌾'],\n",
    "    ['🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌾'],\n",
    "    ['🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌾'],\n",
    "    ['🌲', '🌲', '🌲', '🌲', '🌲', '🌲', '🌾']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**what do you expect the policy would be?** Think about it for a bit. This will help you with your programming and debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States and State Representation\n",
    "\n",
    "The canonical pieces of a State Space Search problem are the States, Actions, Transitions and Costs. \n",
    "\n",
    "We'll start with the state representation. For the navigation problem, a state is the current position of the agent, `(x,y)`. The entire set of possible states is implicitly represented by the world map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions and Transitions\n",
    "\n",
    "Next we need to specify the actions. In general, there are a number of different possible action sets in such a world. The agent might be constrained to move north/south/east/west or diagonal moves might be permitted as well (or really anything). When combined with the set of States, the *permissible* actions forms the Transition set.\n",
    "\n",
    "Rather than enumerate the Transition set directly, for this problem it's easier to calculate the available actions and transitions on the fly. This can be done by specifying a *movement model* as offsets to the current state and then checking to see which of the potential successor states are actually permitted. This can be done in the successor function mentioned in the pseudocode.\n",
    "\n",
    "One such example of a movement model is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVES = [(0,-1), (1,0), (0,1), (-1,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costs\n",
    "\n",
    "We can encode the costs described above in a `Dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COSTS = { '🌾': 1, '🌲': 3, '🪨': 5, '🐊': 7, '🗻': float('inf')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification\n",
    "\n",
    "You will implement a function called `a_star_search` that takes the parameters and returns the value as specified below. The return value is going to look like this:\n",
    "\n",
    "`[(0,1), (0,1), (0,1), (1,0), (1,0), (1,0), (1,0), (1,0), (1,0), (0,1), (0,1), (0,1)]`\n",
    "\n",
    "You should also implement a function called `pretty_print_path`. \n",
    "The `pretty_print_path` function prints an ASCII representation of the path generated by the `a_star_search` on top of the terrain map. \n",
    "For example, for the test world, it would print this:\n",
    "\n",
    "```\n",
    "⏬🌲🌲🌲🌲🌲🌲\n",
    "⏬🌲🌲🌲🌲🌲🌲\n",
    "⏬🌲🌲🌲🌲🌲🌲\n",
    "⏩⏩⏩⏩⏩⏩⏬\n",
    "🌲🌲🌲🌲🌲🌲⏬\n",
    "🌲🌲🌲🌲🌲🌲⏬\n",
    "🌲🌲🌲🌲🌲🌲🎁\n",
    "```\n",
    "\n",
    "using ⏩,⏪,⏫ ⏬ to represent actions and `🎁` to represent the goal. (Note the format of the output...there are no spaces, commas, or extraneous characters). You are printing the path over the terrain.\n",
    "This is an impure function (it does not return anything).\n",
    "\n",
    "Note that in Python:\n",
    "```\n",
    "> a = [\"*\", \"-\", \"*\"]\n",
    "> \"\".join(a)\n",
    "*-*\n",
    "```\n",
    "Do not print raw data structures; do not insert unneeded/requested spaces!\n",
    "\n",
    "### Additional comments\n",
    "\n",
    "As Python is an interpreted language, you're going to need to insert all of your functions *before* the actual `a_star_search` function implementation. \n",
    "Do not make unwarranted assumptions (for example, do not assume that the start is always (0, 0).\n",
    "Do not refer to global variables, pass them as parameters (functional programming).\n",
    "\n",
    "Simple and correct is better than inefficient and incorrect, or worse, incomplete.\n",
    "For example, you can use a simple List, with some helper functions, as a Stack or a Queue or a Priority Queue.\n",
    "Avoid the Python implementations of HeapQ, PriorityQueue implementation unless you are very sure about what you're doing as they require *immutable* keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Callable\n",
    "from copy import deepcopy\n",
    "from queue import PriorityQueue\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*add as many markdown and code cells here as you need for helper functions. We have added `heuristic` for you*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_neighbors\n",
    "\n",
    "`get_neighbors` looks at the current node and gets its neighbors that are within the world space **Used by**: [a_star_search](#a_star_search)\n",
    "\n",
    "* **position** tuple: the position of the current node.\n",
    "* **moves**: list: list of tuples that contain all the possible action moements in the world.\n",
    "* **world**: list: list of lists that contain the mapping of the world.\n",
    "\n",
    "**returns** List: list of tuples that states the current node's neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(position: tuple, moves: List[Tuple[int, int]], world: List[List[str]]) -> list:\n",
    "    \n",
    "    possible_neighbors = [tuple(np.subtract(position, move))\n",
    "                          for move in moves]\n",
    "    neighbors = []\n",
    "    # Checks if it is within the world and then appends to actual neighbors\n",
    "    for neighbor in possible_neighbors:\n",
    "        if (neighbor[0] in range(len(world)) and \n",
    "            neighbor[1] in range(len(world[0]))):\n",
    "            neighbors.append(neighbor)\n",
    "    return neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "start = (0,0)\n",
    "assert get_neighbors(start,MOVES,test_world) == [(0,1), (1,0)]\n",
    "start = (0,3)\n",
    "assert get_neighbors(start,MOVES,test_world) == [(0,4), (0,2), (1,3)]\n",
    "start = (7,7)\n",
    "assert get_neighbors(start,MOVES,test_world) == []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"heuristic\"></a>\n",
    "## heuristic\n",
    "`heuristic` - In this world, the only movements allowed are left, right, up and down, therefor the best type of heuristic function for this would be using the Mahattan Distance which is defined as h(n) = | x-i | + | y-j |. **Used by**: [a_star_search](#a_star_search)\n",
    "\n",
    "f(n) = g(n) + h(n) \n",
    "* **h(n)** : Heuristic from Greedy Search, estimated cost of the cheapest path from the state at node n to goal state \n",
    "* **g(n)** : Path cost from the initial State to node n (cost of path taken so far)\n",
    "* **f(n)** : estimated cost of the best path that continues \n",
    "\n",
    "**returns** int : the heuristic value h(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(start: tuple, goal: tuple) -> int:\n",
    "    h = abs(start[0] - goal[0]) + abs(start[1] - goal[1])\n",
    "    return h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assertions/unit tests\n",
    "start = (0,0)\n",
    "assert heuristic(start,(3,3)) == 6\n",
    "start = (0,0)\n",
    "assert heuristic(start,(2,2)) == 4\n",
    "start = (3,3)\n",
    "assert heuristic(start,(3,3)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"a_star_search\"></a>\n",
    "## a_star_search\n",
    "`a_star_search` is a best-first search algorithm that uses f(n) = g(n) + h(n). Whether `a_star_search` is cost-optimal depends on the ley property that the `heuristic` is admissible, an admissible heuristic is one that never overestimates the cost to reach the goal. The algorithm starts off in the Initial State, at the frontier it then gets the neighbors and calculates the f(n), the estimated cost of the best path that it continues. After evaluating all the neighbors, the one with the lowest cost will then be pushed into the priority queue. Now the next state in the priority queue is evaluated and etc. The algorithm continues until it reaches the goal State. \n",
    "\n",
    "* **h(n)** : Heuristic from Greedy Search, estimated cost of the cheapest path from the state at node n to goal state \n",
    "* **g(n)** : Path cost from the initial State to node n (cost of path taken so far)\n",
    "* **f(n)** : estimated cost of the best path that continues \n",
    "\n",
    "* **world** List[List[str]]: the actual context for the navigation problem.\n",
    "* **start** Tuple[int, int]: the starting location of the bot, `(x, y)`.\n",
    "* **goal** Tuple[int, int]: the desired goal position for the bot, `(x, y)`.\n",
    "* **costs** Dict[str, int]: is a `Dict` of costs for each type of terrain in **world**.\n",
    "* **moves** List[Tuple[int, int]]: the legal movement model expressed in offsets in **world**.\n",
    "* **heuristic** Callable: is a heuristic function that returns an estimate of the total cost $f(x)$ from the start to the goal through the current node, $x$. The heuristic function might change with the movement model. EDITED: Estimated cost of getting from n to the goal\n",
    "\n",
    "\n",
    "**returns** List[Tuple[int, int]]: the offsets needed to get from start state to the goal as a `List`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_star_search( world: List[List[str]], start: Tuple[int, int], goal: Tuple[int, int], costs: Dict[str, int], moves: List[Tuple[int, int]], heuristic: Callable) -> List[Tuple[int, int]]:\n",
    "    frontier = PriorityQueue()\n",
    "    frontier.put(start, 0)\n",
    "    \n",
    "    path = {start: None}\n",
    "    g_n = {start: 0}\n",
    "    while not frontier.empty():\n",
    "        current_node = frontier.get()\n",
    "        if current_node == goal:\n",
    "            final = [current_node]\n",
    "            while current_node in path:\n",
    "                current_node = path[current_node]\n",
    "                final.append(current_node)\n",
    "            final = final[::-1]\n",
    "            path_actions = [tuple(np.subtract(j,i)) for i, j in zip(final[1:], final[2:])]\n",
    "            final_path_actions = []\n",
    "            for action in path_actions:\n",
    "                reversed_action = action[::-1]\n",
    "                final_path_actions.append(reversed_action)\n",
    "            break\n",
    "        neighbors = get_neighbors(current_node, moves, world)\n",
    "        for neighbor in neighbors:\n",
    "\n",
    "            new_g = g_n[current_node] + costs.get(world[neighbor[0]][neighbor[1]])\n",
    "    \n",
    "            if neighbor not in g_n or new_g < g_n[neighbor]:\n",
    "                g_n[neighbor] = new_g\n",
    "                priority = new_g + heuristic(neighbor, goal)\n",
    "                frontier.put(neighbor,priority)\n",
    "                path[neighbor] = current_node\n",
    "            \n",
    "    return final_path_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretty_print_path\n",
    "\n",
    "`pretty_print_path` is a function used to print out the world and demonstrate the path returned from `a_star_search` This function also uses the cost dictionary along with the path's action tuples to calculated the total path cost. \n",
    "\n",
    "* **world** List[List[str]]: the world (terrain map) for the path to be printed upon.\n",
    "* **path** List[Tuple[int, int]]: the path from start to goal, in offsets.\n",
    "* **start** Tuple[int, int]: the starting location for the path.\n",
    "* **goal** Tuple[int, int]: the goal location for the path.\n",
    "* **costs** Dict[str, int]: is a `Dict` of costs for each type of terrain in **world**.\n",
    "\n",
    "**returns** int - The path cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_solution( world: List[List[str]], path: List[Tuple[int, int]], start: Tuple[int, int], goal: Tuple[int, int], costs: Dict[str, int] ) -> int:\n",
    "    ### YOUR SOLUTION HERE ###\n",
    "    dictionary = {(0,1):'⏬', (1,0):'⏩', (0,-1):'⏫', (-1,0):'⏪', goal:'🎁'}\n",
    "    \n",
    "    total_cost = 0\n",
    "    for action in path:\n",
    "            world[start[1]][start[0]] = dictionary.get(action)\n",
    "            start = tuple(np.add(start, action))\n",
    "            total_cost += costs.get(world[start[1]][start[0]])\n",
    "            world[start[1]][start[0]] = dictionary.get(action)\n",
    "            \n",
    "    world[goal[1]][goal[0]] = dictionary.get(goal)     \n",
    "    \n",
    "    for row in world:\n",
    "        row_string = ''\n",
    "        for char in row:\n",
    "            row_string += f'{str(char):<1} '.replace('.', ' ')\n",
    "        print(row_string)\n",
    "    return total_cost # replace with the real value!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1. \n",
    "\n",
    "Execute `a_star_search` and `print_path` for the `test_world`.\n",
    "\n",
    "If you change any values while developing your code, make sure you change them back! (Better yet, don't do it. Copy them elsewhere and change the values, then delete those experiments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏬ 🌲 🌲 🌲 🌲 🌲 🌲 \n",
      "⏬ 🌲 🌲 🌲 🌲 🌲 🌲 \n",
      "⏬ 🌲 🌲 🌲 🌲 🌲 🌲 \n",
      "⏩ ⏩ ⏩ ⏩ ⏩ ⏩ ⏬ \n",
      "🌲 🌲 🌲 🌲 🌲 🌲 ⏬ \n",
      "🌲 🌲 🌲 🌲 🌲 🌲 ⏬ \n",
      "🌲 🌲 🌲 🌲 🌲 🌲 🎁 \n",
      "total path cost: 12\n",
      "[(0, 1), (0, 1), (0, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (0, 1), (0, 1), (0, 1)]\n"
     ]
    }
   ],
   "source": [
    "test_start = (0, 0)\n",
    "test_goal = (len(test_world[0]) - 1, len(test_world) - 1)\n",
    "test_path = a_star_search(test_world, test_start, test_goal, COSTS, MOVES, heuristic)\n",
    "test_path_cost = pretty_print_solution(test_world, test_path, test_start, test_goal, COSTS)\n",
    "print(f\"total path cost: {test_path_cost}\")\n",
    "print(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Execute `a_star_search` and `print_path` for the `full_world`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏬ 🌾 🌾 🌾 🌾 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌾 🌾 🌾 🌾 🌾 🌾 🌾 🌾 🌾 🌾 🌾 🌾 \n",
      "⏬ 🌾 🌾 🌾 🌾 🌾 🌾 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌾 🌾 🗻 🗻 🗻 🗻 🗻 🗻 🗻 🌾 🌾 \n",
      "⏬ 🌾 🌾 🌾 🗻 🗻 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🗻 🗻 🗻 🪨 🪨 🪨 🗻 🗻 🪨 🪨 \n",
      "⏬ 🌾 🌾 🌾 🪨 🗻 🗻 🗻 🌲 🌲 🌲 🌲 🐊 🐊 🌲 🌲 🌲 🌲 🌲 🌾 🌾 🪨 🪨 🗻 🗻 🪨 🌾 \n",
      "⏬ 🌾 🌾 🪨 🪨 🗻 🗻 🌲 🌲 🌾 🌾 🐊 🐊 🐊 🐊 🌲 🌲 🌲 🌾 🌾 🌾 🪨 🗻 🗻 🗻 🪨 🌾 \n",
      "⏬ 🪨 🪨 🪨 🗻 🗻 🪨 🪨 🌾 🌾 🌾 🌾 🐊 🐊 🐊 🐊 🐊 🌾 🌾 🌾 🌾 🌾 🪨 🗻 🪨 🌾 🌾 \n",
      "⏬ 🪨 🪨 🗻 🗻 🪨 🪨 🌾 🌾 🌾 🌾 🪨 🗻 🗻 🗻 🐊 🐊 🐊 🌾 🌾 🌾 🌾 🌾 🪨 🌾 🌾 🌾 \n",
      "⏬ 🌾 🪨 🪨 🪨 🪨 🪨 🌾 🌾 🌾 🌾 🌾 🌾 🪨 🗻 🗻 🗻 🐊 🐊 🐊 🌾 🌾 🪨 🪨 🪨 🌾 🌾 \n",
      "⏬ 🌾 🌾 🪨 🪨 🪨 🌾 🌾 🌾 🌾 🌾 🌾 🪨 🪨 🗻 🗻 🌾 🐊 🐊 🌾 🌾 🪨 🪨 🪨 🌾 🌾 🌾 \n",
      "⏬ 🌾 🌾 🐊 🐊 🐊 🌾 🌾 🪨 🪨 🪨 🗻 🗻 🗻 🗻 🌾 🌾 🌾 🐊 🌾 🪨 🪨 🪨 🌾 🌾 🌾 🌾 \n",
      "⏬ 🌾 🐊 🐊 🐊 🐊 🐊 🌾 🪨 🪨 🗻 🗻 🗻 🪨 🌾 🌾 🌾 🌾 🌾 🪨 🗻 🗻 🗻 🪨 🌾 🌾 🌾 \n",
      "⏬ 🐊 🐊 🐊 🐊 🐊 🌾 🌾 🪨 🗻 🗻 🪨 🌾 🌾 🌾 🌾 🐊 🐊 🌾 🌾 🪨 🗻 🗻 🪨 🌾 🌾 🌾 \n",
      "⏬ 🐊 🐊 🐊 🐊 🌾 🌾 🪨 🪨 🗻 🗻 🪨 🌾 🐊 🐊 🐊 🐊 🌾 🌾 🌾 🪨 🗻 🪨 🌾 🌾 🌾 🌾 \n",
      "⏬ 🐊 🐊 🐊 🐊 🌾 🌾 🪨 🌲 🌲 🪨 🌾 🌾 🌾 🌾 🐊 🐊 🐊 🐊 🌾 🌾 🪨 🌾 🌾 🌾 🌾 🌾 \n",
      "⏩ ⏬ 🌾 🌾 🗻 🌾 🌾 🌲 🌲 🌲 🌲 🪨 🪨 🪨 🪨 🌾 🐊 🐊 🐊 🌾 🌾 🪨 🗻 🪨 🌾 🌾 🌾 \n",
      "🌾 ⏬ 🌾 🗻 🗻 🗻 🌲 🌲 🌲 🌲 🌲 🌲 🗻 🗻 🗻 🪨 🪨 🌾 🐊 🌾 🪨 🗻 🗻 🪨 🌾 🌾 🌾 \n",
      "🌾 ⏬ 🗻 🗻 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🗻 🗻 🗻 🌾 🌾 🗻 🗻 🗻 🌾 🌾 🌾 🌾 🌾 \n",
      "🌾 ⏬ 🌾 🗻 🗻 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🗻 🗻 🗻 🗻 🌾 🌾 🌾 🌾 🌾 🌾 🌾 \n",
      "🌾 ⏬ 🌾 🗻 🗻 🗻 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌲 🌾 🌾 🌾 🪨 🪨 🌾 🌾 🌾 🌾 🌾 🌾 🌾 🌾 \n",
      "🌾 ⏬ 🌾 🌾 🗻 🗻 🗻 🌲 🌲 🌲 🌲 🌲 🌲 🌾 🌾 🌾 🌾 🌾 🌾 🌾 🌾 🌾 🌾 🐊 🐊 🐊 🐊 \n",
      "🌾 ⏬ 🪨 🪨 🪨 🪨 🗻 🗻 🌲 🌲 🌲 🌲 🌲 🌾 🗻 🌾 🌾 🌾 🌾 🌾 🐊 🐊 🐊 🐊 🐊 🐊 🐊 \n",
      "🌾 ⏩ ⏩ ⏬ 🪨 🪨 🪨 🗻 🗻 🗻 🌲 🌲 🗻 🗻 🌾 🌾 🌾 🌾 🌾 🌾 🐊 🐊 🐊 🐊 🐊 🐊 🐊 \n",
      "🌾 🌾 🌾 ⏩ ⏩ ⏩ ⏬ 🪨 🪨 🗻 🗻 🗻 🗻 🌾 🌾 🌾 🌾 🪨 🪨 🌾 🌾 🐊 🐊 🐊 🐊 🐊 🐊 \n",
      "🌾 🪨 🪨 🌾 🌾 🪨 ⏬ 🪨 🪨 🪨 🌾 🌾 🌾 🌾 🌾 🪨 🪨 🗻 🗻 🪨 🪨 🌾 🐊 🐊 🐊 🐊 🐊 \n",
      "🪨 🗻 🪨 🪨 🪨 🪨 ⏩ ⏩ ⏩ ⏬ 🌾 🗻 🗻 🗻 🪨 🪨 🗻 🗻 🌾 🗻 🗻 🪨 🪨 🐊 🐊 🐊 🐊 \n",
      "🪨 🗻 🗻 🗻 🪨 🌾 🌾 🌾 🌾 ⏬ 🪨 🪨 🗻 🗻 🗻 🗻 🪨 🪨 🪨 🪨 🗻 🗻 🗻 🐊 🐊 🐊 🐊 \n",
      "🪨 🪨 🌾 🌾 🌾 🌾 🌾 🌾 🌾 ⏩ ⏩ ⏩ ⏩ ⏩ ⏩ ⏩ ⏩ ⏩ ⏩ ⏩ ⏩ ⏩ ⏩ ⏩ ⏩ ⏩ 🎁 \n",
      "total path cost: 98\n",
      "[(0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (1, 0), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (0, 1), (1, 0), (1, 0), (0, 1), (1, 0), (1, 0), (1, 0), (0, 1), (0, 1), (1, 0), (1, 0), (1, 0), (0, 1), (0, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0)]\n"
     ]
    }
   ],
   "source": [
    "full_start = (0, 0)\n",
    "full_goal = (len(full_world[0]) - 1, len(full_world) - 1)\n",
    "full_path = a_star_search(full_world, full_start, full_goal, COSTS, MOVES, heuristic)\n",
    "full_path_cost = pretty_print_solution(full_world, full_path, full_start, full_goal, COSTS)\n",
    "print(f\"total path cost: {full_path_cost}\")\n",
    "print(full_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "192px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
